# OLYMPIC-SUMMER-GAMES

This project demonstrates a complete end-to-end data engineering solution on Microsoft Azure using real-world data from the **Paris Olympics 2024**. It covers ingestion, transformation, and deployment of big data using **ADF**, **Azure Data Lake**, **Databricks (PySpark)**, and **Azure DevOps CI/CD**.

## 🚀 Tech Stack

- **Azure Data Factory (ADF)** – Orchestration and ETL pipelines
- **Azure Data Lake Gen2** – Scalable cloud data storage (Bronze/Silver/Gold architecture)
- **Azure Databricks (PySpark)** – Big data processing and transformation
- **Delta Lake & Delta Live Tables** – Curated data layers with versioning
- **Azure DevOps** – CI/CD automation with Git-based workflows

## 📊 Dataset

- Source: Kaggle – [Paris Olympics 2024 Dataset](https://www.kaggle.com/)
- Files Used: `athletes.csv`, `coaches.csv`, `events.csv`, `nocs.csv`

## 🛠️ Features

- Dynamic and parameterized pipelines in ADF
- PySpark-based transformations with filtering, joins, window functions, and aggregations
- CI/CD integration via Azure DevOps (feature branching, pull requests, ARM templates)
- Bronze, Silver, and Gold data zone implementation
- Declarative ETL using Delta Live Tables

## ✅ Outcomes

- Hands-on cloud data engineering experience
- Real-world project aligned with enterprise architecture
- Skill-building in CI/CD, big data processing, and Azure ecosystem

---

